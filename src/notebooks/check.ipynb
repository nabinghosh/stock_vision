{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('market_data.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndianMarketData:\n",
    "    def __init__(self):\n",
    "        # Create directories for data storage\n",
    "        self.base_dir = Path('data')\n",
    "        self.raw_dir = self.base_dir / 'raw'\n",
    "        self.processed_dir = self.base_dir / 'processed'\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        for directory in [self.base_dir, self.raw_dir, self.processed_dir]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Initialize indices from Wikipedia\n",
    "        self.indices = self.get_index_data()\n",
    "        \n",
    "    def get_index_data(self):\n",
    "        \"\"\"Fetch NSE index data from Wikipedia\"\"\"\n",
    "        try:\n",
    "            url = 'https://en.wikipedia.org/wiki/NSE_Indices'\n",
    "            tables = pd.read_html(url)\n",
    "            \n",
    "            # Define known Yahoo Finance symbols\n",
    "            known_symbols = {\n",
    "                'NIFTY 50': '^NSEI',\n",
    "                'NIFTY BANK': '^NSEBANK',\n",
    "                'NIFTY IT': '^CNXIT',\n",
    "                'NIFTY AUTO': '^0P0001PQB7',\n",
    "                'NIFTY FINANCIAL SERVICES': '^CNXFINANCE',\n",
    "                'NIFTY FMCG': '^CNXFMCG',\n",
    "                'NIFTY METAL': '^CNXMETAL',\n",
    "                'NIFTY PHARMA': '^CNXPHARMA'\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"Successfully fetched index data with {len(known_symbols)} indices\")\n",
    "            return known_symbols\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching index data: {e}\")\n",
    "            # Fallback to default indices\n",
    "            return {\n",
    "                'NIFTY 50': '^NSEI',\n",
    "                'NIFTY BANK': '^NSEBANK',\n",
    "                'NIFTY IT': '^CNXIT',\n",
    "                'NIFTY AUTO': '^0P0001PQB7'\n",
    "            }\n",
    "\n",
    "    def get_nifty50_symbols(self):\n",
    "        \"\"\"Get list of Nifty 50 companies with retry mechanism\"\"\"\n",
    "        max_retries = 3\n",
    "        retry_delay = 2\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                nifty50 = pd.read_html('https://en.wikipedia.org/wiki/NIFTY_50')[1]\n",
    "                print(nifty50)\n",
    "                symbols = nifty50['Symbol'].tolist()\n",
    "                print(symbols)\n",
    "                symbols = [f\"{symbol}.NS\" for symbol in symbols]\n",
    "                logger.info(f\"Successfully fetched {len(symbols)} Nifty 50 symbols\")\n",
    "                return symbols\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(retry_delay)\n",
    "                    retry_delay *= 2\n",
    "                else:\n",
    "                    logger.error(\"All attempts to fetch Nifty 50 symbols failed\")\n",
    "                    return []\n",
    "\n",
    "    def fetch_data(self, symbol, start_date, end_date, is_index=False):\n",
    "        \"\"\"Generic data fetching function with retry mechanism\"\"\"\n",
    "        max_retries = 3\n",
    "        retry_delay = 2\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                if is_index:\n",
    "                    df = yf.download(symbol, start=start_date, end=end_date)\n",
    "                else:\n",
    "                    df = yf.Ticker(symbol).history(start=start_date, end=end_date)\n",
    "                \n",
    "                if df is not None and not df.empty:\n",
    "                    df.index = df.index.date\n",
    "                    return df\n",
    "                \n",
    "                logger.warning(f\"Empty data received for {symbol}\")\n",
    "                return None\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed for {symbol}: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(retry_delay)\n",
    "                    retry_delay *= 2\n",
    "                else:\n",
    "                    logger.error(f\"All attempts to fetch data for {symbol} failed\")\n",
    "                    return None\n",
    "\n",
    "    def save_to_csv(self, df, filename):\n",
    "        \"\"\"Save data to CSV with error handling\"\"\"\n",
    "        try:\n",
    "            filepath = self.raw_dir / filename\n",
    "            \n",
    "            # Check if the file already exists\n",
    "            if filepath.exists():\n",
    "                # Append without writing the header\n",
    "                df.to_csv(filepath, mode='a', header=False)\n",
    "                logger.info(f\"Appended data to {filepath}\")\n",
    "            else:\n",
    "                # Write with header\n",
    "                df.to_csv(filepath)\n",
    "                logger.info(f\"Successfully saved data to {filepath}\")\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving data to {filename}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def process_symbol(self, symbol, start_date, end_date, is_index=False):\n",
    "        \"\"\"Process a single symbol\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Processing {'index' if is_index else 'stock'}: {symbol}\")\n",
    "            df = self.fetch_data(symbol, start_date, end_date, is_index)\n",
    "            \n",
    "            if df is not None and not df.empty:\n",
    "                filename = f\"{symbol.replace('^', '').replace('.NS', '')}_{'index' if is_index else 'stock'}_data.csv\"\n",
    "                return self.save_to_csv(df, filename)\n",
    "            \n",
    "            return False\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {symbol}: {e}\")\n",
    "            return False\n",
    "        \n",
    "    def clean_csv_file(self, filename):\n",
    "        \"\"\"Clean up the CSV file by removing duplicate header rows\"\"\"\n",
    "        try:\n",
    "            filepath = self.raw_dir / filename\n",
    "            if filepath.exists():\n",
    "                df = pd.read_csv(filepath)\n",
    "                # Remove rows where 'Ticker' column has the ticker symbol\n",
    "                df = df[df['Ticker'] != '^CNXIT']  # Adjust this based on the actual ticker symbol\n",
    "                df.to_csv(filepath, index=False)\n",
    "                logger.info(f\"Cleaned up {filepath}\")\n",
    "            else:\n",
    "                logger.warning(f\"File {filepath} does not exist.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cleaning CSV file {filename}: {e}\")\n",
    "\n",
    "    def fetch_and_save_all_data(self, start_date, end_date, max_workers=4):\n",
    "        \"\"\"Main function to fetch and save all data using parallel processing\"\"\"\n",
    "        successful_downloads = 0\n",
    "        failed_downloads = 0\n",
    "        \n",
    "        # Process stocks\n",
    "        stock_symbols = self.get_nifty50_symbols()\n",
    "        \n",
    "        # Process both stocks and indices using ThreadPoolExecutor\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit stock processing tasks\n",
    "            stock_futures = {\n",
    "                executor.submit(self.process_symbol, symbol, start_date, end_date): symbol \n",
    "                for symbol in stock_symbols\n",
    "            }\n",
    "            \n",
    "            # Submit index processing tasks\n",
    "            index_futures = {\n",
    "                executor.submit(self.process_symbol, symbol, start_date, end_date, True): name \n",
    "                for name, symbol in self.indices.items()\n",
    "            }\n",
    "            \n",
    "            # Process all futures\n",
    "            for future in as_completed({**stock_futures, **index_futures}):\n",
    "                symbol = stock_futures.get(future) or index_futures.get(future)\n",
    "                try:\n",
    "                    if future.result():\n",
    "                        successful_downloads += 1\n",
    "                    else:\n",
    "                        failed_downloads += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing {symbol}: {e}\")\n",
    "                    failed_downloads += 1\n",
    "\n",
    "        # Clean up index data files\n",
    "        for index_name in self.indices.keys():\n",
    "            self.clean_csv_file(f\"{index_name.replace(' ', '_')}_index_data.csv\")\n",
    "        \n",
    "        logger.info(f\"Download complete. Successful: {successful_downloads}, Failed: {failed_downloads}\")\n",
    "        return successful_downloads, failed_downloads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Set date range for data\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=365*5)  # 5 years of data\n",
    "        \n",
    "        logger.info(f\"Starting data collection from {start_date} to {end_date}\")\n",
    "        \n",
    "        # Initialize and run data collection\n",
    "        market_data = IndianMarketData()\n",
    "        successful, failed = market_data.fetch_and_save_all_data(start_date, end_date)\n",
    "        \n",
    "        logger.info(f\"Data collection completed. Successful: {successful}, Failed: {failed}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error in main: {e }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 17:56:12,032 - INFO - Starting data collection from 2019-10-31 17:56:12.032513 to 2024-10-29 17:56:12.032513\n",
      "2024-10-29 17:56:12,529 - INFO - Successfully fetched index data with 8 indices\n",
      "2024-10-29 17:56:13,272 - INFO - Successfully fetched 50 Nifty 50 symbols\n",
      "2024-10-29 17:56:13,273 - INFO - Processing stock: ADANIENT.NS\n",
      "2024-10-29 17:56:13,276 - INFO - Processing stock: ADANIPORTS.NS\n",
      "2024-10-29 17:56:13,276 - INFO - Processing stock: APOLLOHOSP.NS\n",
      "2024-10-29 17:56:13,277 - INFO - Processing stock: ASIANPAINT.NS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Company name      Symbol  \\\n",
      "0                 Adani Enterprises    ADANIENT   \n",
      "1                 Adani Ports & SEZ  ADANIPORTS   \n",
      "2                  Apollo Hospitals  APOLLOHOSP   \n",
      "3                      Asian Paints  ASIANPAINT   \n",
      "4                         Axis Bank    AXISBANK   \n",
      "5                        Bajaj Auto  BAJAJ-AUTO   \n",
      "6                     Bajaj Finance  BAJFINANCE   \n",
      "7                     Bajaj Finserv  BAJAJFINSV   \n",
      "8                Bharat Electronics         BEL   \n",
      "9                  Bharat Petroleum        BPCL   \n",
      "10                    Bharti Airtel  BHARTIARTL   \n",
      "11             Britannia Industries   BRITANNIA   \n",
      "12                            Cipla       CIPLA   \n",
      "13                       Coal India   COALINDIA   \n",
      "14         Dr. Reddy's Laboratories     DRREDDY   \n",
      "15                    Eicher Motors   EICHERMOT   \n",
      "16                Grasim Industries      GRASIM   \n",
      "17                          HCLTech     HCLTECH   \n",
      "18                        HDFC Bank    HDFCBANK   \n",
      "19                        HDFC Life    HDFCLIFE   \n",
      "20                    Hero MotoCorp  HEROMOTOCO   \n",
      "21              Hindalco Industries    HINDALCO   \n",
      "22               Hindustan Unilever  HINDUNILVR   \n",
      "23                       ICICI Bank   ICICIBANK   \n",
      "24                    IndusInd Bank  INDUSINDBK   \n",
      "25                          Infosys        INFY   \n",
      "26                              ITC         ITC   \n",
      "27                        JSW Steel    JSWSTEEL   \n",
      "28              Kotak Mahindra Bank   KOTAKBANK   \n",
      "29                  Larsen & Toubro          LT   \n",
      "30              Mahindra & Mahindra         M&M   \n",
      "31                    Maruti Suzuki      MARUTI   \n",
      "32                     Nestlé India   NESTLEIND   \n",
      "33                             NTPC        NTPC   \n",
      "34  Oil and Natural Gas Corporation        ONGC   \n",
      "35                       Power Grid   POWERGRID   \n",
      "36              Reliance Industries    RELIANCE   \n",
      "37       SBI Life Insurance Company     SBILIFE   \n",
      "38                  Shriram Finance  SHRIRAMFIN   \n",
      "39              State Bank of India        SBIN   \n",
      "40                       Sun Pharma   SUNPHARMA   \n",
      "41        Tata Consultancy Services         TCS   \n",
      "42           Tata Consumer Products  TATACONSUM   \n",
      "43                      Tata Motors  TATAMOTORS   \n",
      "44                       Tata Steel   TATASTEEL   \n",
      "45                    Tech Mahindra       TECHM   \n",
      "46                    Titan Company       TITAN   \n",
      "47                            Trent       TRENT   \n",
      "48                 UltraTech Cement  ULTRACEMCO   \n",
      "49                            Wipro       WIPRO   \n",
      "\n",
      "                        Sector[12]        Date added[13]  \n",
      "0                  Metals & Mining     30 September 2022  \n",
      "1                         Services     28 September 2015  \n",
      "2                       Healthcare         31 March 2022  \n",
      "3                Consumer Durables      27 April 2012[a]  \n",
      "4               Financial Services         27 March 2009  \n",
      "5   Automobile and Auto Components     1 October 2010[b]  \n",
      "6               Financial Services     29 September 2017  \n",
      "7               Financial Services          2 April 2018  \n",
      "8                    Capital Goods     30 September 2024  \n",
      "9      Oil, Gas & Consumable Fuels    28 October 2002[c]  \n",
      "10               Telecommunication          1 March 2004  \n",
      "11      Fast Moving Consumer Goods      29 March 2019[d]  \n",
      "12                      Healthcare        7 October 1998  \n",
      "13     Oil, Gas & Consumable Fuels       10 October 2011  \n",
      "14                      Healthcare     1 October 2010[e]  \n",
      "15  Automobile and Auto Components          1 April 2016  \n",
      "16          Construction Materials       2 April 2018[f]  \n",
      "17          Information Technology       28 October 2002  \n",
      "18              Financial Services         22 April 1996  \n",
      "19              Financial Services          31 July 2020  \n",
      "20  Automobile and Auto Components     7 October 1998[g]  \n",
      "21                 Metals & Mining         22 April 1996  \n",
      "22      Fast Moving Consumer Goods         22 April 1996  \n",
      "23              Financial Services       25 January 2002  \n",
      "24              Financial Services          1 April 2013  \n",
      "25          Information Technology        7 October 1998  \n",
      "26      Fast Moving Consumer Goods         22 April 1996  \n",
      "27                 Metals & Mining     28 September 2018  \n",
      "28              Financial Services          8 April 2010  \n",
      "29                    Construction   10 December 2004[h]  \n",
      "30  Automobile and Auto Components     18 September 1996  \n",
      "31  Automobile and Auto Components          1 March 2004  \n",
      "32      Fast Moving Consumer Goods  27 September 2019[i]  \n",
      "33                           Power     24 September 2007  \n",
      "34     Oil, Gas & Consumable Fuels         12 April 2004  \n",
      "35                           Power         14 March 2008  \n",
      "36     Oil, Gas & Consumable Fuels         22 April 1996  \n",
      "37              Financial Services     25 September 2020  \n",
      "38              Financial Services         28 March 2024  \n",
      "39              Financial Services         22 April 1996  \n",
      "40                      Healthcare       17 January 2002  \n",
      "41          Information Technology      25 February 2005  \n",
      "42      Fast Moving Consumer Goods      31 March 2021[j]  \n",
      "43  Automobile and Auto Components         22 April 1996  \n",
      "44                 Metals & Mining         22 April 1996  \n",
      "45          Information Technology         28 March 2014  \n",
      "46               Consumer Durables          2 April 2018  \n",
      "47               Consumer Services     30 September 2024  \n",
      "48          Construction Materials     28 September 2012  \n",
      "49          Information Technology  27 September 2013[k]  \n",
      "['ADANIENT', 'ADANIPORTS', 'APOLLOHOSP', 'ASIANPAINT', 'AXISBANK', 'BAJAJ-AUTO', 'BAJFINANCE', 'BAJAJFINSV', 'BEL', 'BPCL', 'BHARTIARTL', 'BRITANNIA', 'CIPLA', 'COALINDIA', 'DRREDDY', 'EICHERMOT', 'GRASIM', 'HCLTECH', 'HDFCBANK', 'HDFCLIFE', 'HEROMOTOCO', 'HINDALCO', 'HINDUNILVR', 'ICICIBANK', 'INDUSINDBK', 'INFY', 'ITC', 'JSWSTEEL', 'KOTAKBANK', 'LT', 'M&M', 'MARUTI', 'NESTLEIND', 'NTPC', 'ONGC', 'POWERGRID', 'RELIANCE', 'SBILIFE', 'SHRIRAMFIN', 'SBIN', 'SUNPHARMA', 'TCS', 'TATACONSUM', 'TATAMOTORS', 'TATASTEEL', 'TECHM', 'TITAN', 'TRENT', 'ULTRACEMCO', 'WIPRO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 17:56:13,814 - INFO - Appended data to data\\raw\\ADANIENT_stock_data.csv\n",
      "2024-10-29 17:56:13,820 - INFO - Processing stock: AXISBANK.NS\n",
      "2024-10-29 17:56:13,870 - INFO - Appended data to data\\raw\\APOLLOHOSP_stock_data.csv\n",
      "2024-10-29 17:56:13,870 - INFO - Appended data to data\\raw\\ADANIPORTS_stock_data.csv\n",
      "2024-10-29 17:56:13,873 - INFO - Processing stock: BAJAJ-AUTO.NS\n",
      "2024-10-29 17:56:13,874 - INFO - Processing stock: BAJFINANCE.NS\n",
      "2024-10-29 17:56:13,890 - INFO - Appended data to data\\raw\\ASIANPAINT_stock_data.csv\n",
      "2024-10-29 17:56:13,892 - INFO - Processing stock: BAJAJFINSV.NS\n",
      "2024-10-29 17:56:14,028 - INFO - Appended data to data\\raw\\AXISBANK_stock_data.csv\n",
      "2024-10-29 17:56:14,029 - INFO - Processing stock: BEL.NS\n",
      "2024-10-29 17:56:14,142 - INFO - Appended data to data\\raw\\BAJFINANCE_stock_data.csv\n",
      "2024-10-29 17:56:14,154 - INFO - Appended data to data\\raw\\BAJAJ-AUTO_stock_data.csv\n",
      "2024-10-29 17:56:14,155 - INFO - Processing stock: BPCL.NS\n",
      "2024-10-29 17:56:14,157 - INFO - Processing stock: BHARTIARTL.NS\n",
      "2024-10-29 17:56:14,160 - INFO - Appended data to data\\raw\\BAJAJFINSV_stock_data.csv\n",
      "2024-10-29 17:56:14,164 - INFO - Processing stock: BRITANNIA.NS\n",
      "2024-10-29 17:56:14,228 - INFO - Appended data to data\\raw\\BEL_stock_data.csv\n",
      "2024-10-29 17:56:14,229 - INFO - Processing stock: CIPLA.NS\n",
      "2024-10-29 17:56:14,342 - INFO - Appended data to data\\raw\\BPCL_stock_data.csv\n",
      "2024-10-29 17:56:14,362 - INFO - Processing stock: COALINDIA.NS\n",
      "2024-10-29 17:56:14,410 - INFO - Appended data to data\\raw\\BRITANNIA_stock_data.csv\n",
      "2024-10-29 17:56:14,411 - INFO - Appended data to data\\raw\\BHARTIARTL_stock_data.csv\n",
      "2024-10-29 17:56:14,416 - INFO - Processing stock: DRREDDY.NS\n",
      "2024-10-29 17:56:14,432 - INFO - Processing stock: EICHERMOT.NS\n",
      "2024-10-29 17:56:14,450 - INFO - Appended data to data\\raw\\CIPLA_stock_data.csv\n",
      "2024-10-29 17:56:14,450 - INFO - Processing stock: GRASIM.NS\n",
      "2024-10-29 17:56:14,667 - INFO - Appended data to data\\raw\\COALINDIA_stock_data.csv\n",
      "2024-10-29 17:56:14,676 - INFO - Processing stock: HCLTECH.NS\n",
      "2024-10-29 17:56:14,711 - INFO - Appended data to data\\raw\\EICHERMOT_stock_data.csv\n",
      "2024-10-29 17:56:14,714 - INFO - Processing stock: HDFCBANK.NS\n",
      "2024-10-29 17:56:14,749 - INFO - Appended data to data\\raw\\DRREDDY_stock_data.csv\n",
      "2024-10-29 17:56:14,756 - INFO - Processing stock: HDFCLIFE.NS\n",
      "2024-10-29 17:56:14,763 - INFO - Appended data to data\\raw\\GRASIM_stock_data.csv\n",
      "2024-10-29 17:56:14,764 - INFO - Processing stock: HEROMOTOCO.NS\n",
      "2024-10-29 17:56:14,876 - INFO - Appended data to data\\raw\\HCLTECH_stock_data.csv\n",
      "2024-10-29 17:56:14,877 - INFO - Processing stock: HINDALCO.NS\n",
      "2024-10-29 17:56:14,911 - INFO - Appended data to data\\raw\\HDFCBANK_stock_data.csv\n",
      "2024-10-29 17:56:14,913 - INFO - Processing stock: HINDUNILVR.NS\n",
      "2024-10-29 17:56:14,965 - INFO - Appended data to data\\raw\\HDFCLIFE_stock_data.csv\n",
      "2024-10-29 17:56:14,972 - INFO - Processing stock: ICICIBANK.NS\n",
      "2024-10-29 17:56:14,984 - INFO - Appended data to data\\raw\\HEROMOTOCO_stock_data.csv\n",
      "2024-10-29 17:56:14,985 - INFO - Processing stock: INDUSINDBK.NS\n",
      "2024-10-29 17:56:15,148 - INFO - Appended data to data\\raw\\HINDALCO_stock_data.csv\n",
      "2024-10-29 17:56:15,150 - INFO - Processing stock: INFY.NS\n",
      "2024-10-29 17:56:15,233 - INFO - Appended data to data\\raw\\ICICIBANK_stock_data.csv\n",
      "2024-10-29 17:56:15,233 - INFO - Appended data to data\\raw\\HINDUNILVR_stock_data.csv\n",
      "2024-10-29 17:56:15,240 - INFO - Processing stock: ITC.NS\n",
      "2024-10-29 17:56:15,242 - INFO - Processing stock: JSWSTEEL.NS\n",
      "2024-10-29 17:56:15,248 - INFO - Appended data to data\\raw\\INDUSINDBK_stock_data.csv\n",
      "2024-10-29 17:56:15,249 - INFO - Processing stock: KOTAKBANK.NS\n",
      "2024-10-29 17:56:15,472 - INFO - Appended data to data\\raw\\ITC_stock_data.csv\n",
      "2024-10-29 17:56:15,476 - INFO - Processing stock: LT.NS\n",
      "2024-10-29 17:56:15,481 - INFO - Appended data to data\\raw\\KOTAKBANK_stock_data.csv\n",
      "2024-10-29 17:56:15,485 - INFO - Processing stock: M&M.NS\n",
      "2024-10-29 17:56:15,495 - INFO - Appended data to data\\raw\\JSWSTEEL_stock_data.csv\n",
      "2024-10-29 17:56:15,496 - INFO - Processing stock: MARUTI.NS\n",
      "2024-10-29 17:56:15,709 - INFO - Appended data to data\\raw\\M&M_stock_data.csv\n",
      "2024-10-29 17:56:15,715 - INFO - Processing stock: NESTLEIND.NS\n",
      "2024-10-29 17:56:15,738 - INFO - Appended data to data\\raw\\MARUTI_stock_data.csv\n",
      "2024-10-29 17:56:15,746 - INFO - Processing stock: NTPC.NS\n",
      "2024-10-29 17:56:15,754 - INFO - Appended data to data\\raw\\LT_stock_data.csv\n",
      "2024-10-29 17:56:15,755 - INFO - Processing stock: ONGC.NS\n",
      "2024-10-29 17:56:15,932 - INFO - Appended data to data\\raw\\NTPC_stock_data.csv\n",
      "2024-10-29 17:56:15,938 - INFO - Processing stock: POWERGRID.NS\n",
      "2024-10-29 17:56:15,950 - INFO - Appended data to data\\raw\\NESTLEIND_stock_data.csv\n",
      "2024-10-29 17:56:15,951 - INFO - Processing stock: RELIANCE.NS\n",
      "2024-10-29 17:56:16,006 - INFO - Appended data to data\\raw\\ONGC_stock_data.csv\n",
      "2024-10-29 17:56:16,007 - INFO - Processing stock: SBILIFE.NS\n",
      "2024-10-29 17:56:16,019 - INFO - Appended data to data\\raw\\INFY_stock_data.csv\n",
      "2024-10-29 17:56:16,020 - INFO - Processing stock: SHRIRAMFIN.NS\n",
      "2024-10-29 17:56:16,167 - INFO - Appended data to data\\raw\\POWERGRID_stock_data.csv\n",
      "2024-10-29 17:56:16,168 - INFO - Processing stock: SBIN.NS\n",
      "2024-10-29 17:56:16,258 - INFO - Appended data to data\\raw\\RELIANCE_stock_data.csv\n",
      "2024-10-29 17:56:16,260 - INFO - Processing stock: SUNPHARMA.NS\n",
      "2024-10-29 17:56:16,263 - INFO - Appended data to data\\raw\\SHRIRAMFIN_stock_data.csv\n",
      "2024-10-29 17:56:16,267 - INFO - Processing stock: TCS.NS\n",
      "2024-10-29 17:56:16,276 - INFO - Appended data to data\\raw\\SBILIFE_stock_data.csv\n",
      "2024-10-29 17:56:16,279 - INFO - Processing stock: TATACONSUM.NS\n",
      "2024-10-29 17:56:16,402 - INFO - Appended data to data\\raw\\SBIN_stock_data.csv\n",
      "2024-10-29 17:56:16,403 - INFO - Processing stock: TATAMOTORS.NS\n",
      "2024-10-29 17:56:16,500 - INFO - Appended data to data\\raw\\TCS_stock_data.csv\n",
      "2024-10-29 17:56:16,505 - INFO - Processing stock: TATASTEEL.NS\n",
      "2024-10-29 17:56:16,529 - INFO - Appended data to data\\raw\\SUNPHARMA_stock_data.csv\n",
      "2024-10-29 17:56:16,530 - INFO - Appended data to data\\raw\\TATACONSUM_stock_data.csv\n",
      "2024-10-29 17:56:16,531 - INFO - Processing stock: TECHM.NS\n",
      "2024-10-29 17:56:16,532 - INFO - Processing stock: TITAN.NS\n",
      "2024-10-29 17:56:16,598 - INFO - Appended data to data\\raw\\TATAMOTORS_stock_data.csv\n",
      "2024-10-29 17:56:16,599 - INFO - Processing stock: TRENT.NS\n",
      "2024-10-29 17:56:16,719 - INFO - Appended data to data\\raw\\TITAN_stock_data.csv\n",
      "2024-10-29 17:56:16,727 - INFO - Processing stock: ULTRACEMCO.NS\n",
      "2024-10-29 17:56:16,767 - INFO - Appended data to data\\raw\\TECHM_stock_data.csv\n",
      "2024-10-29 17:56:16,772 - INFO - Processing stock: WIPRO.NS\n",
      "2024-10-29 17:56:16,793 - INFO - Appended data to data\\raw\\TATASTEEL_stock_data.csv\n",
      "2024-10-29 17:56:16,797 - INFO - Processing index: ^NSEI\n",
      "2024-10-29 17:56:16,813 - INFO - Appended data to data\\raw\\TRENT_stock_data.csv\n",
      "2024-10-29 17:56:16,814 - INFO - Processing index: ^NSEBANK\n",
      "2024-10-29 17:56:16,993 - INFO - Appended data to data\\raw\\WIPRO_stock_data.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "2024-10-29 17:56:17,027 - INFO - Processing index: ^CNXIT\n",
      "2024-10-29 17:56:17,041 - INFO - Appended data to data\\raw\\ULTRACEMCO_stock_data.csv\n",
      "2024-10-29 17:56:17,045 - INFO - Appended data to data\\raw\\NSEI_index_data.csv\n",
      "2024-10-29 17:56:17,045 - INFO - Appended data to data\\raw\\NSEBANK_index_data.csv\n",
      "2024-10-29 17:56:17,047 - INFO - Processing index: ^0P0001PQB7\n",
      "2024-10-29 17:56:17,048 - INFO - Processing index: ^CNXFINANCE\n",
      "2024-10-29 17:56:17,050 - INFO - Processing index: ^CNXFMCG\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "2024-10-29 17:56:17,056 - ERROR - \n",
      "1 Failed download:\n",
      "2024-10-29 17:56:17,057 - ERROR - ['^0P0001PQB7']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "2024-10-29 17:56:17,061 - WARNING - Empty data received for ^CNXFMCG\n",
      "[*********************100%***********************]  1 of 1 completed2024-10-29 17:56:17,062 - INFO - Processing index: ^CNXMETAL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "2024-10-29 17:56:17,065 - ERROR - \n",
      "2 Failed downloads:\n",
      "\n",
      "2024-10-29 17:56:17,065 - ERROR - \n",
      "2 Failed downloads:\n",
      "2024-10-29 17:56:17,066 - WARNING - Attempt 1 failed for ^CNXIT: No objects to concatenate\n",
      "2024-10-29 17:56:17,066 - WARNING - Attempt 1 failed for ^CNXFINANCE: No objects to concatenate\n",
      "2024-10-29 17:56:17,067 - WARNING - Attempt 1 failed for ^0P0001PQB7: No objects to concatenate\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "2024-10-29 17:56:17,280 - INFO - Successfully saved data to data\\raw\\CNXMETAL_index_data.csv\n",
      "2024-10-29 17:56:17,282 - INFO - Processing index: ^CNXPHARMA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "2024-10-29 17:56:17,339 - INFO - Successfully saved data to data\\raw\\CNXPHARMA_index_data.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "2024-10-29 17:56:19,082 - ERROR - \n",
      "2 Failed downloads:\n",
      "2024-10-29 17:56:19,082 - ERROR - ['^CNXFINANCE', '^0P0001PQB7']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "\n",
      "2024-10-29 17:56:19,082 - ERROR - \n",
      "2 Failed downloads:\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "2024-10-29 17:56:19,085 - WARNING - Empty data received for ^CNXIT\n",
      "2024-10-29 17:56:19,087 - ERROR - \n",
      "2 Failed downloads:\n",
      "2024-10-29 17:56:19,087 - ERROR - ['^CNXFINANCE', '^0P0001PQB7']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "2024-10-29 17:56:19,089 - ERROR - ['^CNXFINANCE', '^0P0001PQB7']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "2024-10-29 17:56:19,092 - WARNING - Empty data received for ^CNXFINANCE\n",
      "2024-10-29 17:56:19,095 - WARNING - Empty data received for ^0P0001PQB7\n",
      "2024-10-29 17:56:19,097 - WARNING - File data\\raw\\NIFTY_50_index_data.csv does not exist.\n",
      "2024-10-29 17:56:19,099 - WARNING - File data\\raw\\NIFTY_BANK_index_data.csv does not exist.\n",
      "2024-10-29 17:56:19,100 - WARNING - File data\\raw\\NIFTY_IT_index_data.csv does not exist.\n",
      "2024-10-29 17:56:19,101 - WARNING - File data\\raw\\NIFTY_AUTO_index_data.csv does not exist.\n",
      "2024-10-29 17:56:19,102 - WARNING - File data\\raw\\NIFTY_FINANCIAL_SERVICES_index_data.csv does not exist.\n",
      "2024-10-29 17:56:19,104 - WARNING - File data\\raw\\NIFTY_FMCG_index_data.csv does not exist.\n",
      "2024-10-29 17:56:19,105 - WARNING - File data\\raw\\NIFTY_METAL_index_data.csv does not exist.\n",
      "2024-10-29 17:56:19,105 - WARNING - File data\\raw\\NIFTY_PHARMA_index_data.csv does not exist.\n",
      "2024-10-29 17:56:19,106 - INFO - Download complete. Successful: 54, Failed: 4\n",
      "2024-10-29 17:56:19,107 - INFO - Data collection completed. Successful: 54, Failed: 4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
